{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.marsDB\n",
    "db.mars.delete_many({})\n",
    "mars_collection = db.marsDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib.request import urlopen\n",
    "    import pandas as pd\n",
    "    from splinter import Browser\n",
    "    \n",
    "    global totaldict\n",
    "    \n",
    "    news_p()\n",
    "    news_title()\n",
    "    featured_img_url()\n",
    "    mars_weather()\n",
    "    mars_facts()\n",
    "    mars_hemispheres()\n",
    "    \n",
    "    totaldict = {\n",
    "        \"title\": news_titlex,\n",
    "        \"description\": news_px,\n",
    "        \"featured image\": featured_img_urlx,\n",
    "        \"weather\": mars_weatherx,\n",
    "        \"hemisphere\": hemisphere_img_urlsx    \n",
    "    }\n",
    "    \n",
    "    \n",
    "    return totaldict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_p():\n",
    "    global news_px\n",
    "    \n",
    "    source = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "    html = urlopen(source)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    news_px = []\n",
    "    for i in soup.find_all('div',  \"rollover_description_inner\"):\n",
    "        news_px.append(i.text.strip('\\n'))\n",
    "    \n",
    "    return news_px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_title():\n",
    "    global news_titlex\n",
    "    \n",
    "    source = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "    html = urlopen(source)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    news_titlex = []\n",
    "    for i in soup.find_all('div', \"content_title\"):\n",
    "        news_titlex.append(i.text.strip('\\n'))\n",
    "        \n",
    "    return news_titlex    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featured_img_url():\n",
    "    #Splinter time\n",
    "    \n",
    "    #Note: Actually not splinter time. I spent a while trying to get the 'chromedriver' executable to work. \n",
    "    #It is added to the PATH. I know how to do this and have done it. \n",
    "    #However, it still errors out. I am using beautifulSoup instead to do this part. \n",
    "    \n",
    "    global featured_img_urlx\n",
    "    \n",
    "    source = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "\n",
    "    html = urlopen(source)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    featured_img_urlx = 'https://www.jpl.nasa.gov' +soup.find('a', \"fancybox\")['data-fancybox-href']\n",
    "    \n",
    "    return featured_img_urlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_weather():\n",
    "    global mars_weatherx\n",
    "    \n",
    "    source = 'https://twitter.com/marswxreport?lang=en'\n",
    "\n",
    "    html = urlopen(source)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    mars_weatherx = soup.find('p', 'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text').text\n",
    "    return mars_weatherx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_facts():\n",
    "\n",
    "    #Note: The first time I made this code, this worked fine. I used the \"to_html()\" function on the dataframe and all was well. However, now the website gives a 500 error.\n",
    "    #As we learned in class, a 500 error means this is the server's problem. For now, the code does not include this section, but it would work fine once their\n",
    "    #website is back running. \n",
    "    \n",
    "    global marsdfx\n",
    "    \n",
    "    try:\n",
    "        source = 'http://space-facts.com/mars/'\n",
    "\n",
    "        html = urlopen(source)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "        headerlist = []\n",
    "        datalist = []\n",
    "\n",
    "        for i in soup.findAll('td', \"column-1\"):\n",
    "            headerlist.append(i.text)\n",
    "    \n",
    "        for i in soup.findAll('td', \"column-2\"):\n",
    "            datalist.append(i.text.strip('\\n'))    \n",
    "    \n",
    "        marsdict = dict(zip(headerlist,datalist))    \n",
    "    \n",
    "        marsdfx = pd.DataFrame(marsdict, index = [0])\n",
    "    \n",
    "        return marsdfx\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        marsdfx = \"space-facts.com is not responding, unfortunately.\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mars_hemispheres():\n",
    "     ##Mars Hemispheres\n",
    "# With this one, I imagine some people will use Splinter. However, I am familiar with BeautifulSoup, so I found it easier to do the following. \n",
    "    \n",
    "    global hemisphere_img_urlsx\n",
    "    \n",
    "    source = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    html = urlopen(source)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "      \n",
    "    targetlist = []\n",
    "    titlelist = []\n",
    "\n",
    "    for i in soup.findAll('a', \"itemLink product-item\", href=True):\n",
    "    \n",
    "        source = 'https://astrogeology.usgs.gov' + i['href']\n",
    "        html = urlopen(source)\n",
    "        souptwo = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "        for i in souptwo.findAll('h2', 'title'):\n",
    "            titlelist.append(i.text)\n",
    "    \n",
    "        for j in souptwo.findAll('ul'):\n",
    "            if j.a.has_attr('target'):\n",
    "                targetlist.append(j.a['href'])\n",
    "            \n",
    "#pretty happy with this bit of code. This could scale up a lot as well.  \n",
    "\n",
    "    hemisphere_img_urlsx = []\n",
    "\n",
    "    for i in range(len(titlelist)):\n",
    "        hemisphere_img_urlsx.append(\n",
    "            {\"title\": titlelist[i],\n",
    "            \"img_url\": targetlist[i]})\n",
    "\n",
    "    return hemisphere_img_urlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': [\"NASA's Opportunity Rover Mission on Mars Comes to End\",\n",
       "  \"NASA's InSight Places First Instrument on Mars\",\n",
       "  'NASA Announces Landing Site for Mars 2020 Rover',\n",
       "  'Opportunity Hunkers Down During Dust Storm',\n",
       "  'NASA Finds Ancient Organic Material, Mysterious Methane on Mars',\n",
       "  'NASA Invests in Visionary Technology '],\n",
       " 'description': [\"NASA's Opportunity Mars rover mission is complete after 15 years on Mars. Opportunity's record-breaking exploration laid the groundwork for future missions to the Red Planet.\",\n",
       "  'In deploying its first instrument onto the surface of Mars, the lander completes a major mission milestone.',\n",
       "  'After a five-year search, NASA has chosen Jezero Crater as the landing site for its upcoming Mars 2020 rover mission.',\n",
       "  \"It's the beginning of the end for the planet-encircling dust storm on Mars. But it could still be weeks, or even months, before skies are clear enough for NASA's Opportunity rover to recharge its batteries and phone home. \",\n",
       "  'NASA’s Curiosity rover has found evidence on Mars with implications for NASA’s search for life.',\n",
       "  'NASA is investing in technology concepts, including several from JPL, that may one day be used for future space exploration missions.'],\n",
       " 'featured image': 'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19346_ip.jpg',\n",
       " 'weather': 'InSight sol 106 (2019-03-15) low -96.3ºC (-141.4ºF) high -15.9ºC (3.3ºF)\\nwinds from the SW at 4.1 m/s (9.3 mph) gusting to 12.4 m/s (27.8 mph)\\npressure at 7.20 hPapic.twitter.com/OkdWbeg6uw',\n",
       " 'hemisphere': [{'title': 'Cerberus Hemisphere Enhanced',\n",
       "   'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
       "  {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "   'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
       "  {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "   'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
       "  {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "   'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x259e5ddcd08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.mars.insert_one(totaldict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
